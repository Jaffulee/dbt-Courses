C6-L7-dbt build command explainer



At this point, we've created models in our dbt project.

We've defined our sources, and we've added data tests to both our models and to our sources.

We might have a project that looks something like this. Here's a sample tag where we can see in green our source notes, and

in blue, we can see all the models that are built on top of our sources.

We can see in this case, we have two staging models, one called stage jaffle shop orders and one called stage Jaffle Shop customers.

Each staging model is built on top of a single source, and they contain the same level of detail.

Then we have some downstream models as well.

We've got a dim customers model, which is going to be joining these two staging models together. And then we might have an add customers model, which is going to be doing some aggregations on top of the dim customers model.

So far, when we've been developing, we've been running the command dbt run to create all of our models and then the command dbt test to apply data test to all of our models and to apply

data test to our sources.

Maybe we added some selection syntax in there, but in general, we've been separating our commands of dbt run and dbt test.

Now this has some pretty big implications for when we get into deployment later on, but I wanted to introduce a new way of running our commands by essentially combining dbt run and test together.

This new way is going to be our dbt build command, which is what this section is all about.

But for now, let's focus on dbt run and dbt test, and really understand what they're doing.

Let's imagine as we're developing in the IDE, we first run the command dbt run to create all of our models in our warehouse.

When that's done, we run the dbt test command to apply all of our data tests all based on our sample tag.

So here's what would happen.

It's going to run our first set of models, and in this case, that's our stage customers and stage orders models.

Once those are complete, DBT is going to run the next set of models, and it'll continue doing that in DAG order.

So it's going to run dim customers and then add customers, etcetera, until it runs all the models in your project.

Once all those models have been run, which implies they've been created in your warehouse, then we're finally adding our data tests.

If we have data tests on our sources, those would come first with the dbt test command because we're still going in DAG order.

Then it's going to run data tests on our first set of models, and in this case, that's our staging models.

Then it'll run data tests on dim customers, the next set, and it's going to continue in DAG order until it finishes.

So what happens if a data test fails on an early model?

Well, if a data test fails on stage customers, we have a problem because we already ran all of our models first.

That downstream model, dim customers, and ad customers already got created

and were already built on top of the staging model that had failing data.

We can see that this could be a pretty big problem, especially if that failing record is due to maybe an issue with a primary key. We can't switch up the order of our commands here.

We can't do a dbt test before a dbt run because the data test is going to apply data tests to the models as they exist in your warehouse, and we first have to run them in order to get them to exist in the warehouse. So we have a problem with this method.

The new ish method of combining these commands is the dbt build command.

Now it adds a couple of extra complexities, but right now we're going to focus on what it does to run our models and to perform our data tests.

With the dbt build command, the difference is it's going to go in DAG order, but it's going to combine all of our commands, including dbt run and dbt test, and follow our models in DAG order.

So the first thing it will do is apply data tests to our sources.

Assuming those data tests pass, then it's going to run our first set of models and then apply data tests to our first set of models.

Assuming everything is successful again at this point, it's going to do the same at the next layer.

So it'll run this set of models, in this case, dim customers, and then it will apply data tests to dim customers, and then it's gonna run add customers, and then it'll apply data test to add customers,

so on and so forth.

So now what happens if a data test fails on an early model?

This time, our downstream model is not going to run if our data test fails in an early stage customer's model because that happened before this downstream model ran. The data test failure would cause our job to halt. Now this is gonna be a pretty big deal when we get to deployment later on because we're going to be ensuring that we're not building our downstream marts on top of models that have failing data tests.

So let's take a demo of this command in DBT cloud.

So we can see dim customers here at the end of my lineage.

If I were to do the dbt build command, the first thing it's going to do is run any data test that I have on these sources here, and then it's going to continue going layer by layer, running our models, and then applying data tests to them.

It'll run these staging models and apply data tests on these staging models, and then it'll run fact orders and apply data tests on fact orders. And then it'll finally get to running and then running data tests on dim customers.

So we can do this

with the command dbt build and with our usual selection syntax.

Or instead of writing all that out, I could just hit this drop down here that says build and select the build this model plus upstream and hit that.

So let's do that and see what it comes up with.

So we can see that it applies the usual selection syntax that we're used to. The plus sign indicating upstream ancestors and dim customers indicating the model that we wanna build after all of its upstream ancestors.

And let's scan through the results here.

So it did run a data test, two data tests actually, on all of my

sources almost immediately.

At the same time, it was able to run this view stage payments because stage payments does not depend on any sources that have data tests.

After it ran data tests on my sources, it ran their corresponding staging models.

It also ran and applied the data tests that are on those staging models even in accepted values and in not null and in relationships, all kinds of data tests.

And then finally, it built fact orders and dim customers in my warehouse, but it didn't apply any data tests because I did not assign any. So just to make it extra clear, I want to show you what happens if we had a failing test in the stage orders model. So I'm going to navigate to my stage JaffleShop dot yaml file and I'm going to add a failing test to the order staging model.

A data test that I know is going to fail is adding a unique data test to this status column.

I know that this data test is gonna fail. So we saved this, and now let's rerun our command.

Let's go back to Dim customers, click the build button, and let's click build this model plus upstream and take a look at what it does. Now I know that this is going to make the data test fail this time. And because we're using the build command, once this data test fails on my staging model, DBT will skip any downstream models, and it will halt the rest of my job or in this case the rest of my command.

We can see here this failing data test, it returned five failing results and downstream of it were fact orders and dim customers.

So those did not get run because there was a data test that failed upstream of those two models.

So we can see why using the dbt build command can be a powerful way to ensure that we're both running and applying data tests to our models, but also making sure that we're not building downstream models on top of maybe some staging models or anything else upstream that has issues with failing data tests.
