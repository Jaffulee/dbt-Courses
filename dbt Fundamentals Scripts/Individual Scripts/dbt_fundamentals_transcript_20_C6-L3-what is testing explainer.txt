C6-L3-what is testing explainer

Data tests in analytics engineering are assertions that you have about your data. It's critical that these assertions are true so that whatever decisions are being made on those final models can be trusted.

This gives people the confidence that the data that they're looking at is in fact reliable.

You're probably already doing this in your data career.

It might look like exporting a CSV, opening a file in Excel, and then creating maybe a check column to make sure that the values across multiple columns meet your assertions.

It could be that after your table has materialized, you're running a a select distinct query against that to make sure that you've captured all of the payment methods in a particular column.

It could also be just scrolling through the table to make sure that it meets your assertions and maybe trying to catch a little bug here or there.

This data testing mindset is crucial to making sure that you can trust your data and stand behind its quality.

However, it's particularly difficult to scale that across your project.

You can't always download a CSV and then run a check against it manually. It's just not gonna work when you have hundreds of thousands of models.

That's where data testing in dbt comes in.

dbt's data tests are run with the command dbt test and that will run all of the data tests in your project against the latest materialization of your models.

You can construct these data tests in development.

So maybe you write a model and then you write a data test against that model. You can make sure that the transformation code does what you expect and that the underlying data fits your assertions at the time of development.

This gives you as the dbt developer confidence to merge that into your main or master branch and then run that in production.

And once you're running that code in production, the data test configuration or the writing of your data tests is in that same code base.

You can continue to run those assertions as often as the models are being refreshed.

This gives you the confidence that those models feeding important dashboards can be trusted for your team.

So let's dive into some of the specifics.

There are two main classifications of data tests in dbt.

These are singular and generic.

Singular data tests as the name implies are very specific and are applied to probably one maybe two models.

They assert something really specific about the logic in that particular model.

This is not something that you'd want to use across multiple models. We'll touch on that a little bit later.

So singular data tests are something one off that you want to write really specifically for maybe a really important revenue dashboard.

The other classification of data tests are generic data tests.

These are the highly scalable types of data tests.

Rather than writing the logic out, you're just actually writing a couple lines of YAML code and that applies a data test to a particular model or column.

There are four types of generic data tests that come with dbt.

These are unique, not null, accepted values, and relationships.

These four are really easy to apply in your project right away.

We recommend using unique and not null on your primary keys to make sure that you don't produce any breaking joints downstream or any fan outs as you try to build things downstream.

So we have singular and generic as those two classifications of data tests. And in that generic data test column, you have these four with dbt, but there are packages that you can explore that have a ton of testing that a lot of different organizations use. And you can even write your own custom generic data tests. We're gonna need a little bit more learning around Jinja and macros to be able to touch on that, so we can't touch on that quite yet. But once you get your dbt fundamentals badge, check out our Jinja and Macros course at courses dot get dbt dot com.

So we'll step back for a moment.

Data testing in dbt allows you to take that same data testing mindset that you already have and scale it in development.

Then you can also scale that in deployment so that you can trust your data on a daily and a weekly basis. You can focus on getting good sleep and then also building something net new rather than fixing something that you've just found out broke through a Slack message.
